#开题报告（无格式版）
by Hence@Lancet

###选题的背景和意义

**爬虫技术的复杂性与多样性**
在以数据为中心的信息时代，如何快速廉价地获取大量有效的数据，是维持高度数据依赖的组织的竞争力的关键。而在真实互联网环境，数据往往是不均匀地散落在以web为代表的互联网的各个角落中。为了更快更廉价的获取数据，很多互联网组织和个人开发了各式各样的网络爬虫（crawler）来抓取他们感兴趣的数据。爬虫在互联网数据传播过程中起到了至关重要的作用。

现有爬虫种类多，爬取的策略也具有很高的复杂性和多样性。爬虫一般可以按其特点分为四类：通用网络爬虫，聚焦网络爬虫，增量式网络爬虫，深层网络爬虫。最常见的爬取策略是广度优先策略和深度优先策略。除此此外，比较常见的聚焦网络爬虫，甚至会对访问页面和链接的重要性进行评分，并以此作为页面爬取先后的顺序的参考依据【引用】。

Paul在他的论文中提出了Fish-Search算法【Information Retrieval in Distributed Hypertexts】，以页面内容与爬虫的聚焦主题的相关性作为度量标准。Page rank算法主要用于对搜索引擎搜索到的内容进行结果排序，也可以用于评价链接的重要性。Rennie 和 McCallum在他们的工作中，将增强学习（reinforcement learning)引入聚焦爬虫，他们试图通过机器学习找到一组策略，使得对于该策略的激励达到最优解。Diligenti则提出一种通过建立语境图来描述不同网页之间相关度的算法，以此作为确定访问顺序的参考。

爬虫技术的复杂性和多样性也意味着反爬虫技术的复杂性。

**恶意爬虫带来的威胁**
网络中同样充斥着大量恶意的爬虫，他们要么多线程高并发地请求服务器，要么抓取一些敏感的或者高价值的数据，转手将数据倒卖给商业竞争对手。因此，针对爬虫反制措施的重要性也凸显了出来。据资料显示，每年的三月份，正处在在大量硕士需要撰写论文的时间节点，网络着大量应届毕业生写的劣质爬虫，导致很多数据业务相关的网站在三月份访问量大幅度增加。有一部分失控爬虫，不断地像相关网站发送大量请求，造成的带宽的严重占用和流量资源的损耗。今年十月份爆出的马蜂窝评论数据涉嫌造假事件，其数据来源就是通过爬虫，从其竞争对手的网站上抓取的。在涉嫌欺诈的同时，也给其竞争对手带来大量的经济损失。
此外，一部分黑客在攻击网站之前，会通过通用爬虫爬取网站的所有可访问资源，并尝试对其中的参数进行模糊测试。尽早发现带有恶意payload攻击的爬虫，能够在真实攻击发生的早期，进行有效的监测和加固。




**爬虫技术的更新与迭代**


随着headless browser工具的兴起，以及以selenium为主的自动化web测试工具的出现，使得爬虫技术也从原始的静态网页处理方式，逐渐进化到能够与动态的javascript进行复杂交互的状态。这也使得大部分基于javascript脚本混淆（javascipt obfuscate）的反爬虫技术失去了原有的优势。此外，大部分学术界提出的【加引用】爬虫检测策略，往往基于流量日志，是非实时的（offline）检测机制，即不能对爬虫行为做出及时的反馈，也会在随后的离线分析中损耗大量的人力成本。

网络中充斥着大量的网络代理节点，大量的爬虫会在爬取网站过程中不断更改访问的IP地址，使得原本针对IP封锁的方案往往达不到预期的效果，一旦误封正常用户的IP地址，可能造成用户群体的流失。即使是基于CAPTCHA验证码的访问验证，也可以通过打码平台的技术支持在一定程度上进行绕过，而且会影响到正常用户的访问体验。

随着爬虫技术的更新与迭代，甚至是反反爬虫技术的逐渐成熟，现有的反爬虫检测技术已经不能满足当下严峻形势的需求，而爬虫处理技术过于单一，使得网站维护者们在反爬虫的战争中占尽劣势。


**针对爬虫攻击的可行性**


**反爬虫系统的意义和难点**




###相关技术研究现状
* 爬虫识别技术研究现状
* 浏览指纹技术研究现状
* 二进制漏洞挖掘技术现状



###论文的研究内容及拟采用的技术方案
反爬虫系统设计图
实时识别与序列识别解决方案
爬虫溯源技术
爬虫漏洞挖掘与利用
系统部署方案
系统评估方案

###关键技术
动态符号执行与模糊测试





###论文研究计划


###主要参考文献